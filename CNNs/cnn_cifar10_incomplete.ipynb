{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks with Cifar-10\n",
    "\n",
    "Convolutional Neural Network (CNNs, ConvNets) are built to work with spatial data, where the ordering and organization of information matters. Using traditional NNs for image processing requires a \"flattening\" approach, where each pixel corresponds with an input node. In contrast, data is fed into CNNs as a matrix (or tensor), instead of as a flat vector. In this lesson, we apply CNNs to classify images in the [Cifar-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html), which is one of the first datasets created for computer vision and is often used as a benchmark in many ML papers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%run -i tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels, test_images, test_labels = load_data() # defined in tools.py\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: (50000, 32, 32, 3)\n",
      "Train labels: 50000\n",
      "Test images: (10000, 32, 32, 3)\n",
      "Test labels 10000\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images:\", train_images.shape)\n",
    "print(\"Train labels:\", len(train_labels)) \n",
    "print(\"Test images:\", test_images.shape)\n",
    "print(\"Test labels\", len(test_labels))\n",
    "print(\"Number of classes:\", len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def show_image(index):\n",
    "    print(classes[train_labels[index]])\n",
    "    plot = plt.imshow(train_images[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 1000 \n",
    "show_image(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train = train_images.astype('float32')\n",
    "X_test = test_images.astype('float32')\n",
    "\n",
    "# TODO: Normalize Features: Convert Pixels from the range 0-255 to 0-1\n",
    "X_train /= 255.\n",
    "X_test /= 255.\n",
    "# TODO: One-Hot Encoding for Labels: ['cat', 'dog'] => [(0,1), (1,0)]\n",
    "y_train = keras.utils.to_categorical(train_labels)\n",
    "y_test = keras.utils.to_categorical(test_labels)\n",
    "# TODO: Shuffle Data\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_test, y_test = shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "# Shorten Dataset (We would use all data in practice, but we don't have enough time :)\n",
    "PERCENT_DATA_USED = .10 \n",
    "\n",
    "num_train = int(PERCENT_DATA_USED * len(X_train))\n",
    "num_test = int(PERCENT_DATA_USED * len(X_test))\n",
    "X_train = X_train[:num_train]\n",
    "y_train = y_train[:num_train]\n",
    "X_test = X_test[:num_test]\n",
    "y_test = y_test[:num_test]\n",
    "\n",
    "print(len(X_train), len(y_train), len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Baseline\n",
    "\n",
    "Can you beat the CAIS++ API?  We modified the code that we used to create the model in the first lesson so that it is compatible with Cifar-10.  See if you can beat it.  The CAIS++ API uses a strategy called [transfer learning](https://medium.com/kansas-city-machine-learning-artificial-intelligen/an-introduction-to-transfer-learning-in-machine-learning-7efd104b6026), where we start from a model trained on the [imagenet](https://en.wikipedia.org/wiki/ImageNet) dataset.  We \"freeze\" the convolutional layers of the model, so that those values will not be updated by training.  Finally, we add a new \"head\" to our model, which outputs the probability of 10 classes instead of the original 1000 used in imagenet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nicol\\Anaconda3\\envs\\math499\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 1, 1, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 21,934,570\n",
      "Trainable params: 131,786\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model using transfer learning (in tools.py)\n",
    "model = create_model()\n",
    "\n",
    "# Have to resize for InceptionV3 (the pretrained model)\n",
    "# Nearest neighbors method gives the most representative of original\n",
    "X_train_resized = tf.image.resize(X_train, [75, 75], method='nearest') \n",
    "X_test_resized = tf.image.resize(X_test, [75, 75], method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nicol\\Anaconda3\\envs\\math499\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nicol\\Anaconda3\\envs\\math499\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid argument \"steps_per_epoch\" passed to K.function with TensorFlow backend",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\repos\\caispp\\CNNs\\tools.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_resized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m           steps_per_epoch=1)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\math499\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\math499\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m   \u001b[1;31m# Get step function and loop type.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m   \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_execution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m   \u001b[0muse_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_dataset\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m   \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_inputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\math499\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[1;34m(model, mode)\u001b[0m\n\u001b[0;32m    530\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdistributed_training_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_execution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_execution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\math499\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m   2274\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_make_execution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2276\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2277\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2278\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\math499\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2229\u001b[0m             \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2230\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train_function'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2231\u001b[1;33m             **self._function_kwargs)\n\u001b[0m\u001b[0;32m   2232\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train_function'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\math499\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[0;32m   3476\u001b[0m         msg = ('Invalid argument \"%s\" passed to K.function with TensorFlow '\n\u001b[0;32m   3477\u001b[0m                'backend') % key\n\u001b[1;32m-> 3478\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3479\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mGraphExecutionFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid argument \"steps_per_epoch\" passed to K.function with TensorFlow backend"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'],\n",
    "             steps_per_epoch=1)\n",
    "\n",
    "model.fit(X_train_resized, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_resized, y_test),\n",
    "          steps_per_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "\n",
    "- [Convolutional Layers](https://keras.io/layers/convolutional/) \n",
    "    - filters: number of kernals (feature_detectors) in the layer\n",
    "    - kernal_size: size of the kernal\n",
    "    - activation: relu activation function typically used\n",
    "    - padding: how to perserve information in borders\n",
    "    - strides: how to slide kernal over the input (step size)\n",
    "- [Pooling layers](https://keras.io/layers/pooling/)\n",
    "   - max pooling: takes only the maximum pixel value from a region of pixels\n",
    "   - pool_size: region of pixels to consider\n",
    "- [Dropout](https://keras.io/layers/core/#dropout) \n",
    "    - randomly drop neurons during training, helps prevent overfitting\n",
    "    - rate: percentage of neurons to drop\n",
    "- [Batch norm layer](https://keras.io/layers/normalization/)\n",
    "    - normalizes data at a given point in the network, helps prevent overfitting\n",
    "- [Dense Layer](https://keras.io/layers/core/#dense) \n",
    "    - regular fully-connected layer in traditional NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, AveragePooling2D, Dropout, BatchNormalization, Flatten, Dense\n",
    "from keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "#TODO: Create CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Flatten())\n",
    "##########################################\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "#TODO: Compile network\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########################################\n",
    "#TODO: Train model\n",
    "model.fit(X_train_resized, y_train,\n",
    "          steps_per_epoch=64,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_resized, y_test), validation_steps=10)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
